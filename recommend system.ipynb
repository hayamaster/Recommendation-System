{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0ed6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import ast as ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "945f3b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>overview</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>170277</td>\n",
       "      <td>Bumbling navy officer Lieutenant Humphrey Fair...</td>\n",
       "      <td>Up the Creek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>25973</td>\n",
       "      <td>It's Valentine's Day and Tomhas big plans. He'...</td>\n",
       "      <td>What Love Is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>132641</td>\n",
       "      <td>Ten years into a marriage, the wife is disappo...</td>\n",
       "      <td>Wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>59142</td>\n",
       "      <td>A reporter stumbles on a runaway heiress whose...</td>\n",
       "      <td>You Can't Run Away from It</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>47590</td>\n",
       "      <td>Young and beautiful girl (Anna Sten), lives ne...</td>\n",
       "      <td>The Girl with the Hat Box</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                           overview  \\\n",
       "0          862  Led by Woody, Andy's toys live happily in his ...   \n",
       "1         8844  When siblings Judy and Peter discover an encha...   \n",
       "2        15602  A family wedding reignites the ancient feud be...   \n",
       "3        31357  Cheated on, mistreated and stepped on, the wom...   \n",
       "4        11862  Just when George Banks has recovered from his ...   \n",
       "...        ...                                                ...   \n",
       "29995   170277  Bumbling navy officer Lieutenant Humphrey Fair...   \n",
       "29996    25973  It's Valentine's Day and Tomhas big plans. He'...   \n",
       "29997   132641  Ten years into a marriage, the wife is disappo...   \n",
       "29998    59142  A reporter stumbles on a runaway heiress whose...   \n",
       "29999    47590  Young and beautiful girl (Anna Sten), lives ne...   \n",
       "\n",
       "                             title  \n",
       "0                        Toy Story  \n",
       "1                          Jumanji  \n",
       "2                 Grumpier Old Men  \n",
       "3                Waiting to Exhale  \n",
       "4      Father of the Bride Part II  \n",
       "...                            ...  \n",
       "29995                 Up the Creek  \n",
       "29996                 What Love Is  \n",
       "29997                         Wife  \n",
       "29998   You Can't Run Away from It  \n",
       "29999    The Girl with the Hat Box  \n",
       "\n",
       "[30000 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read two datasets\n",
    "movies_ori = pd.read_csv(\"movies_metadata.csv\", encoding='UTF-8')\n",
    "ratings_ori = pd.read_csv(\"ratings_small.csv\")\n",
    "\n",
    "## Preprocessing (Clean the datasets)\n",
    "# Missing value\n",
    "# remove records of movies without title.\n",
    "title_mask = movies_ori['title'].isna()\n",
    "df_movies = movies_ori.loc[title_mask == False]\n",
    "# remove records of movies with wrong 'id'\n",
    "movieId_mask = df_movies.index[[df_movies['id'].str.contains('-')]].tolist()\n",
    "df_movies.drop(movieId_mask, inplace=True)\n",
    "# fill 'NaN' value of all records of columns 'overview' and 'tagline' with ''\n",
    "df_movies['overview'] = df_movies['overview'].fillna('')\n",
    "df_movies['tagline'] = df_movies['tagline'].fillna('')\n",
    "# convert values of 'id' datatype str to int\n",
    "df_movies['id'] = pd.to_numeric(df_movies['id'])\n",
    "# convert values of 'genres' datatype dict to str, and abstract values\n",
    "df_movies['genres'] = df_movies['genres'].apply(ast.literal_eval)\n",
    "df_movies['genres'] = df_movies['genres'].apply(lambda x:[d['name'] for d in x]).apply(lambda x:' '.join(x))\n",
    "# change column name 'id' to 'movieId' & 'tagline' to 'keywords'\n",
    "df_movies.rename(columns={'id':'movieId'}, inplace=True) \n",
    "df_movies.rename(columns={'tagline':'keywords'}, inplace=True)\n",
    "# Features selection\n",
    "df_movies = df_movies[['movieId', 'title', 'overview', 'genres', 'keywords', 'vote_average', 'vote_count']]\n",
    "df_ratings = ratings_ori.iloc[:, :-1]\n",
    "# Merge two datasets 'df_movies' & 'df_ratings'\n",
    "df = pd.merge(df_ratings, df_movies[['movieId', 'title']], on='movieId')\n",
    "\n",
    "\n",
    "## Datasets for each model and preprocessing\n",
    "# dataset for euclidean distance\n",
    "df_euclidean = df.pivot_table(index='movieId', columns='userId', values='rating').fillna(-1)\n",
    "# dataset for cosine similarity (CBF)\n",
    "df_cos = df_movies[['movieId', 'overview', 'title']].head(30000)\n",
    "df_cos = df_cos.reset_index(drop=True)\n",
    "# dataset for cosine similarity (CF item-based)\n",
    "df_cos_item = df.pivot_table(index='title', columns='userId', values='rating').fillna(0)\n",
    "# dataset for matrix factorization\n",
    "df_mf = df.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "# dataset for apriori\n",
    "def encode_ratings(x):  \n",
    "    if x <= 0: \n",
    "        return 0\n",
    "    return 1\n",
    "df_apriori = df.drop_duplicates(['userId', 'title']) # drop duplicated values in 'userId' & 'title'\n",
    "df_apriori = df_apriori.pivot_table(index='userId', columns='title', values='rating').fillna(0).astype('int64')\n",
    "df_apriori = df_apriori.applymap(encode_ratings)  # encoding values to 0 or 1\n",
    "# dataset for content based filtering\n",
    "df_cbf = df_movies\n",
    "\n",
    "\n",
    "df_cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "10fbf6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Collaborative Filtering\n",
    "## Euclidean distance (item-based)\n",
    "def euclidean(data, title):\n",
    "    # movie title로 movieId 가져오기\n",
    "    index = df_cos[df_cos['title'] == title].index\n",
    "    movie_id= list(df_cos.loc[index, 'movieId'])[0]\n",
    "    # simiality function\n",
    "    def sim_distance(data, n1, n2):  \n",
    "        sum = 0\n",
    "        # i 값은 df_euclidean 데이터셋의 선택한 row(movieId)중 평점값이 >=0 값들의 index(userId)\n",
    "        for i in data.loc[n1, data.loc[n1, :]>=0].index:\n",
    "            # n2 = input movieId와 값이 다른 movieId\n",
    "            if data.loc[n2, i]>=0:\n",
    "                sum += math.pow(data.loc[n1, i] - data.loc[n2, i], 2)\n",
    "        return math.sqrt(1/(sum+1)) # return similarity value\n",
    "    \n",
    "    def top_match(data, movieId, rank):\n",
    "        simList = []\n",
    "        # i값은 df_euclidean 데이터셋 절반 중에서의 index(movieId)\n",
    "        # data값이 많아 시간을 줄이기 위해 전체 중 절반만 사용\n",
    "        for i in data.index[-len(data):]:\n",
    "            # input movieId 와 값이 다른 movieId의 similarity값을 simList에 append\n",
    "            if movieId != i:\n",
    "                simList.append((sim_distance(data, movieId, i), i))\n",
    "        simList.sort(reverse=True)\n",
    "        return simList[:rank] # (similarity, movieId) 리스트를 return\n",
    "    \n",
    "    def recommendation(data, movie_id):\n",
    "        res = top_match(data, movie_id, len(data))\n",
    "        score_dic = {}\n",
    "        sim_dic = {}\n",
    "        myList = []\n",
    "        for sim, mv in res:\n",
    "            # similarity >= 0을 때만 실행\n",
    "            if sim < 0:\n",
    "                continue\n",
    "            for movie in data.loc[movie_id, data.loc[movie_id, :] < 0].index:\n",
    "                simSum = 0\n",
    "                if data.loc[mv, movie] >= 0:\n",
    "                    simSum += sim * data.loc[mv, movie]\n",
    "                    score_dic.setdefault(movie, 0)\n",
    "                    score_dic[movie] += simSum\n",
    "                    sim_dic.setdefault(movie, 0)\n",
    "                    sim_dic[movie] += sim\n",
    "        for key in score_dic:\n",
    "            myList.append((score_dic[key] / sim_dic[key], key))\n",
    "        myList.sort(reverse=True)\n",
    "        return myList\n",
    "    # 추천 점수가 가장 높은 순으로 예상평점과 영화제목을 추천 (10개까지)\n",
    "    movieList = []\n",
    "    for rate, m_id in recommendation(data, movie_id):\n",
    "        if list(df_movies.loc[df_movies['movieId']==m_id, 'title']) == []:\n",
    "            continue\n",
    "        movieList.append((rate, df_movies.loc[df_movies['movieId']==m_id, 'title'].values[0]))\n",
    "    print(\"- Collaborative Filtering\")\n",
    "    print(\"- Euclidean distance similarity\\n\")\n",
    "    print(pd.DataFrame(movieList[:10], columns=['Rating', 'Title']))\n",
    "\n",
    "\n",
    "## Cosine similarity (CF item-based)\n",
    "def cos_item(data, title):\n",
    "    # cosine similarity\n",
    "    sim_rate = cosine_similarity(data, data)\n",
    "    sim_rate_df = pd.DataFrame(data=sim_rate, index=data.index, columns=data.index)\n",
    "    sim_rate_df = pd.DataFrame(sim_rate_df[title].sort_values(ascending=False)[1:11]).reset_index()\n",
    "    sim_rate_df.columns = ['Title', 'Cosine Similarity']\n",
    "    sim_rate_df = sim_rate_df[['Cosine Similarity', 'Title']]\n",
    "    print(\"- Collaborative Filtering\")\n",
    "    print(\"- Cosine simiarity (item-based)\\n\")\n",
    "    print(sim_rate_df)\n",
    "    \n",
    "\n",
    "## Matrix Factorization\n",
    "# *parameters mf(data, userId)\n",
    "def mf(df_mat, user_id):\n",
    "    # convert pivot_table dataset to numpy matrix\n",
    "    matrix = df_mat.to_numpy()\n",
    "    rating_mean = np.mean(matrix, axis=1)  # user's mean rating\n",
    "    matrix_mean = matrix - rating_mean.reshape(-1, 1)  # 사용자-영화에 대해 사용자평균 뺀 값\n",
    "    # get U matrix, sigma matrix, Vt transposed matrix from 'svds' meaning 'Truncated SVD'\n",
    "    U, sigma, Vt = svds(matrix_mean, k = 12)\n",
    "    sigma = np.diag(sigma)\n",
    "    # recover original matrix\n",
    "    # dot(U, sigma, Vt) + user's mean rating\n",
    "    svd_ratings = np.dot(np.dot(U, sigma), Vt) + rating_mean.reshape(-1, 1)\n",
    "    df_svd = pd.DataFrame(svd_ratings, columns = df_mat.columns)\n",
    "\n",
    "    def recommendation(data, userId, ori_movie, ori_rating):\n",
    "        # 현재는 index로 적용되어 있어 userId-1\n",
    "        user_row_num = userId - 1\n",
    "        sorted_pre = data.iloc[user_row_num].sort_values(ascending=False)\n",
    "        # abstract datas with same 'userId's from original ratings dataset\n",
    "        user_data = ori_rating[ori_rating.userId == userId]\n",
    "        user_history = user_data.merge(ori_movie, on='movieId').sort_values(['rating'], ascending=False)\n",
    "        user_history = user_history[['userId', 'movieId', 'rating']]\n",
    "        # abstract datas without movie datas users have seen already from original movies dataset\n",
    "        recommendations = ori_movie[~ori_movie['movieId'].isin(user_history['movieId'])]\n",
    "        recommendations = recommendations.merge(pd.DataFrame(sorted_pre).reset_index(), on='movieId')\n",
    "        recommendations = recommendations.rename(columns = {user_row_num: 'Predictions'}).sort_values('Predictions', ascending=False)\n",
    "        recommendations = recommendations[['movieId', 'title', 'Predictions']]\n",
    "\n",
    "        return user_history, recommendations\n",
    "\n",
    "    already_rated, predictions = recommendation(df_svd, user_id, df_movies, df_ratings)\n",
    "#     print(\"User's history\")\n",
    "#     print(already_rated.head(10))\n",
    "    print(\"- Collaborative Filtering\")\n",
    "    print(\"- Matrix Factorization (SVD)\\n\")\n",
    "    predictions = predictions[['Predictions', 'title']]\n",
    "    predictions.columns = ['Predictions rate', 'Title']\n",
    "    print(predictions[:10].reset_index(drop=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f6f46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Contant Based Filtering\n",
    "## Cosine similarity (CBF)\n",
    "def cos(data, title):\n",
    "    # movie title로 movieId 가져오기\n",
    "    index = df_cos[df_cos['title'] == title].index\n",
    "    movie = list(df_cos.loc[index, 'movieId'])[0]\n",
    "    # tf-idf matrix\n",
    "    tfidf = TfidfVectorizer(stop_words='english')  # 불용어 제거\n",
    "    tfidf_mat = tfidf.fit_transform(data['overview']).toarray()\n",
    "    # similarity function\n",
    "    def cos_sim(X, Y):\n",
    "        return np.dot(X,Y)/((norm(X)*norm(Y))+1e-7)  # 분모 0이 안되게 '1e-7'추가\n",
    "\n",
    "    def top_match(data, mv_id, rank=1):\n",
    "        sim = []\n",
    "        for i in range(len(data)):\n",
    "            # input movieId와 다른 movieId의 cosine similarity 구하기\n",
    "            if mv_id != df_cos.loc[i, 'movieId']:\n",
    "                tfidf_idx1 = df_cos[df_cos['movieId'] == mv_id].index\n",
    "                tfidf_idx2 = df_cos[df_cos['movieId'] == df_cos.loc[i, 'movieId']].index\n",
    "                sim.append((cos_sim(data[tfidf_idx2[0]], data[tfidf_idx1[0]]), df_cos.loc[i, 'movieId']))\n",
    "        sim.sort(reverse=True)\n",
    "        return sim[:rank]\n",
    "    \n",
    "    movieList = []\n",
    "    for sim, movie_id in top_match(tfidf_mat, movie, 10):\n",
    "        # cosine similarity가 높은 순서대로 영화 추천\n",
    "        movieList.append((sim, list(data.loc[data['movieId']==movie_id, 'title'])[0]))\n",
    "    print(\"- Contant Based Filtering\")\n",
    "    print(\"- Cosine simiarity\\n\")\n",
    "    print(pd.DataFrame(movieList, columns=['Cosine Similarity', 'Title']).drop_duplicates(['Title'])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f93c4986",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Association Rule Mining\n",
    "## Apriori\n",
    "def apriori(data, name, min_sup=0.08):    \n",
    "    from mlxtend.frequent_patterns import association_rules\n",
    "    from mlxtend.frequent_patterns import apriori\n",
    "    frequent_itemset = apriori(data, min_support=min_sup, use_colnames=True)\n",
    "\n",
    "    rules = association_rules(frequent_itemset, metric='lift', min_threshold=1)\n",
    "    rules.sort_values(by=['lift'], ascending=False, inplace=True)\n",
    "    \n",
    "    df_res = rules[rules['antecedents'].apply(lambda x: len(x) == 1 and next(iter(x)) == name)]\n",
    "    df_res = df_res[df_res['lift'] > 2]\n",
    "    movies = df_res['consequents'].values\n",
    "\n",
    "    movieList = []\n",
    "    for movie in movies:\n",
    "        lift = df_res.loc[df_res['consequents']==movie, ['lift']].values\n",
    "        for title in movie:\n",
    "            if title not in movieList:\n",
    "                movieList.append((round(lift[0][0], 4), title))\n",
    "    print(\"- Association Rule Mining\")\n",
    "    print(\"- Apriori\\n\")\n",
    "    print(pd.DataFrame(movieList, columns=['Lift rate', 'Title']).drop_duplicates(['Title']).reset_index(drop=True)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db1e4b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Association Rule Mining\n",
      "- Apriori\n",
      "\n",
      "   Lift rate                               Title\n",
      "0     3.2129                             48 Hrs.\n",
      "1     3.2129                      Romeo + Juliet\n",
      "2     3.2129                   Three Colors: Red\n",
      "3     3.2092            The Million Dollar Hotel\n",
      "4     3.2092        Dave Chappelle's Block Party\n",
      "5     3.2052                     Monsoon Wedding\n",
      "6     3.2052                               Sissi\n",
      "7     3.2031                 Cockles and Muscles\n",
      "8     3.2031                            Rain Man\n",
      "9     3.2031  Terminator 3: Rise of the Machines\n"
     ]
    }
   ],
   "source": [
    "apriori(df_apriori, 'The Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1921456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Collaborative Filtering\n",
      "- Cosine simiarity (item-based)\n",
      "\n",
      "   Cosine Similarity                Title\n",
      "0           0.664757             Rain Man\n",
      "1           0.656278              48 Hrs.\n",
      "2           0.655502                Sissi\n",
      "3           0.626577     The Conversation\n",
      "4           0.617037    Three Colors: Red\n",
      "5           0.613450      Monsoon Wedding\n",
      "6           0.601700  Cockles and Muscles\n",
      "7           0.599899       Romeo + Juliet\n",
      "8           0.587942          Silent Hill\n",
      "9           0.574302       Batman Returns\n"
     ]
    }
   ],
   "source": [
    "cos_item(df_cos_item, 'The Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6dbcb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590\n",
      "- Contant Based Filtering\n",
      "- Cosine simiarity\n",
      "\n",
      "   Cosine Similarity                      Title\n",
      "0           0.171953            Possible Worlds\n",
      "1           0.156752            The Terrorizers\n",
      "2           0.154630                     Broken\n",
      "3           0.145828  If These Walls Could Talk\n",
      "4           0.139007       A Girl in Every Port\n",
      "5           0.138323                    Macabre\n",
      "6           0.134468             New Year's Eve\n",
      "7           0.133576    Invitation to the Dance\n",
      "8           0.129369          The Lawless Heart\n",
      "9           0.129123               Grand Canyon\n"
     ]
    }
   ],
   "source": [
    "cos(df_cos, 'The Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8ace441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590\n",
      "- Collaborative Filtering\n",
      "- Euclidean distance similarity\n",
      "\n",
      "     Rating                                       Title\n",
      "0  4.942989                              The Ninth Gate\n",
      "1  4.912223                            Ocean's Thirteen\n",
      "2  4.832931  Spring, Summer, Fall, Winter... and Spring\n",
      "3  4.690985                                 Rear Window\n",
      "4  4.625305                                Transamerica\n",
      "5  4.601217                                       Ghost\n",
      "6  4.579262                         Lost in Translation\n",
      "7  4.571828                There's Something About Mary\n",
      "8  4.563083                                  Underworld\n",
      "9  4.558761                                 Bull Durham\n"
     ]
    }
   ],
   "source": [
    "euclidean(df_euclidean, 'The Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a796d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Collaborative Filtering\n",
      "- Matrix Factorization (SVD)\n",
      "\n",
      "   movieId                 title  Predictions\n",
      "0      457                 Sissi     3.000377\n",
      "1      745       The Sixth Sense     2.882037\n",
      "2      380              Rain Man     2.460014\n",
      "3      648  Beauty and the Beast     2.040655\n",
      "4      562              Die Hard     1.966591\n",
      "5      339        Night on Earth     1.857408\n",
      "6     1249         Hollywoodland     1.833415\n",
      "7      802                Lolita     1.828231\n",
      "8        6        Judgment Night     1.790865\n",
      "9       95            Armageddon     1.783874\n"
     ]
    }
   ],
   "source": [
    "mf(df_mf, 86)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
